[{"path":"/articles/hydrographr.html","id":"system-requirements","dir":"Articles","previous_headings":"","what":"System requirements","title":"Getting started with hydrographr","text":"work smoothly hydrographr package, GRASS GIS, GDAL, pktools need installed. can find installation guideline operating systems: Linux Windows macOS","code":""},{"path":"/articles/hydrographr.html","id":"loading-hydrographr","dir":"Articles","previous_headings":"","what":"Loading hydrographr","title":"Getting started with hydrographr","text":"can install hydrographr GitHub repository. install R package yet, install remotes::install_github(). start exploring package load hydrographr.","code":"# If the package remotes is not installed run first: install.packages(\"remotes\")  remotes::install_github(\"glowabio/hydrographr\") library(hydrographr) #> Warning: replacing previous import 'dplyr::as_data_frame' by #> 'igraph::as_data_frame' when loading 'hydrographr'"},{"path":"/articles/linux_system_setup.html","id":"installation-of-the-required-gis-tools","dir":"Articles","previous_headings":"","what":"Installation of the required GIS tools","title":"Setting up the package requirements on Linux","text":"installed GIS tools, please, install using hydrographr. use Ubuntu can copy-paste commands . use another Linux distribution, please, see linked software webpage installation instruction. Add Ubuntugis repository First, add “Ubuntugis” Personal Package Archive (PPA) system’s software sources able install GIS tools available . Next, need tell system pull latest list software archive knows , including PPA just added: Now ready installGDAL, GRASS GIS GNU parallel. Copy paste commands console follow instructions install tools. GDAL GDAL translator library raster vector geospatial data formats comes variety useful command line utilities data translation processing. information check GDAL website. GRASS GIS GRASS GIS powerful raster, vector, geospatial processing engine including tools terrain ecosystem modeling, hydrology processing satellite aerial imagery. detailed installation instructions check GRASS GIS users wiki GRASS GIS website. Please, make sure grass8.2 installed. GRASS GIS addons Copy-paste commands install required addons GRASS GIS. GNU parallel GNU parallel shell tool executing jobs parallel multiple cores. faster processing, hydrographr functions snap_to_subc_segment() extract_zonal_stat() GNU parallel implemented. information check GNU parallel website.","code":"# Add the Ubuntugis PPA sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable # Update the packages list sudo apt update # Install GDAL sudo apt install gdal-bin python3-gdal # Install GRASS GIS sudo apt-get install grass grass-core grass-dev grass-gui grass-doc sudo apt install make  # Install GRASS GIS addons export GRASSEXEC=\"grass --exec\" $GRASSEXEC  g.extension  extension=r.stream.distance $GRASSEXEC  g.extension  extension=r.stream.order $GRASSEXEC  g.extension  extension=r.stream.snap $GRASSEXEC  g.extension  extension=r.stream.basins # Download the latest version of GNU parallel  wget http://ftp.gnu.org/gnu/parallel/parallel-latest.tar.bz2  # Unzip the the .tar file and create a new folder parallel-yyyymmdd sudo tar xjf parallel-latest.tar.bz2 # Check folders and files in the directory and see the date of  # latest version e.g. parallel-20221122 ls # Move to the new created folder parallel-yyyymmdd cd parallel-20221122  sudo ./configure && make sudo make install parallel --citation  #> Academic tradition requires you to cite works you base your article on. #> If you use programs that use GNU Parallel to process data for an article in a #> scientific publication, please cite: #>  #> @software{tange_2022_7347980, #>       author       = {Tange, Ole}, #>       title        = {GNU Parallel 20221122 ('Херсо́н')}, #>       month        = Nov, #>       year         = 2022, #>       note         = {{GNU Parallel is a general parallelizer to run #>                        multiple serial command line programs in parallel #>                        without changing them.}}, #>       publisher    = {Zenodo}, #>       doi          = {10.5281/zenodo.7347980}, #>       url          = {https://doi.org/10.5281/zenodo.7347980} #> }  #> (Feel free to use \\nocite{tange_2022_7347980})  #> This helps funding further development; AND IT WON'T COST YOU A CENT. #> If you pay 10000 EUR you should feel free to use GNU Parallel without citing.  #> More about funding GNU Parallel and the citation notice: #> https://lists.gnu.org/archive/html/parallel/2013-11/msg00006.html #> https://www.gnu.org/software/parallel/parallel_design.html#citation-notice #> https://git.savannah.gnu.org/cgit/parallel.git/tree/doc/citation-notice-faq.txt  #> If you send a copy of your published article to tange@gnu.org, it will be #> mentioned in the release notes of next version of GNU Parallel. #>  #> Type: 'will cite' and press enter.  will cite  #> Thank you for your support: You are the reason why there is funding to #> continue maintaining GNU Parallel. On behalf of future versions of #> GNU Parallel, which would not exist without your support:  #>  THANK YOU SO MUCH  #> It is really appreciated. The citation notice is now silenced."},{"path":"/articles/windows_system_setup.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Setting up the package requirements on Windows","text":"Make sure least 4 GB free disk space. need administrator privileges Windows. must running Windows 10 version 2004 higher Windows 11, otherwise WSL available.","code":""},{"path":"/articles/windows_system_setup.html","id":"installation-of-the-windows-subsystem-for-linux-with-ubuntu","dir":"Articles","previous_headings":"","what":"Installation of the Windows Subsystem for Linux with Ubuntu","title":"Setting up the package requirements on Windows","text":"Open Windows Command Prompt (cmd.exe) administrator mode clicking Start button typing “cmd” search bar.right-click “Command Prompt” select “Run Administrator” highlight result arrow keys press Ctrl+Shift+Enter open command prompt administrative privileges. Enter wsl --install enable features necessary run WSL also directly install Ubuntu distribution Linux, default option WSL. installation complete, restart machine. open “Start” menu click “Ubuntu” open Ubuntu console. Please note Ubuntu get installed automatically, can alternatively visit Windows store (https://aka.ms/wslstore), search Ubuntu, install restart. first time open Ubuntu via “Start” menu prompted create username password Linux distribution. default user account administrator Ubuntu. purpose guideline use hydrographr, can pick name want. Please note whilst entering password, nothing appear screen won’t see typing, completely normal. Window automatically update Linux distribution. update upgrade packages Ubuntu, please copy paste command Ubuntu terminal enter password. done regularly basis. run command sudo system ask password UNIX user account. details installation WSL see . details setting username password see .","code":"# Enable the features necessary to run WSL and  # install the Ubuntu distribution of Linux.  wsl --install  #> Installing: Virtual Machine Platform #> Virtual Machine Platform has been installed. #> Installing: Windows Subsystem for Linux #> Windows Subsystem for Linux has been installed. #> Downloading: WSL Kernel #> Installing: WSL Kernel #> WSL Kernel has been installed. #> Downloading: Ubuntu #> The requested operation is successful. Changes will not be effective until the system is rebooted. #> Installing, this may take a few minutes... #> Please create a default UNIX user account. The username does not need to match your Windows username. #> For more information visit: https://aka.ms/wslusers #> Enter new UNIX username: hydrographr #> New password: #> Retype new password: #> passwd: password updated successfully #> Installation successful! #> To run a command as administrator (user \"root\"), use \"sudo <command>\". #> See \"man sudo_root\" for details. # Update and upgrade packages on Ubuntu sudo apt update && sudo apt upgrade"},{"path":"/articles/windows_system_setup.html","id":"installation-of-the-required-gis-tools-on-the-wsl","dir":"Articles","previous_headings":"","what":"Installation of the required GIS tools on the WSL","title":"Setting up the package requirements on Windows","text":"Next, need install required GIS tools WSL Ubuntu system. can use Ubuntu terminal, PowerShell Windows Command Prompt start installation. use PowerShell Windows Command Prompt use command wsl enter WSL first, exit go back Windows OS installation GIS tools. Add Ubuntugis repository First, add “Ubuntugis” Personal Package Archive (PPA) system’s software sources able install GIS tools available . Next, need tell system pull latest list software archive knows , including PPA just added: Now ready installGDAL, GRASS GIS GNU parallel. Copy paste commands console follow instructions install tools. GDAL GDAL translator library raster vector geospatial data formats comes variety useful command line utilities data translation processing. information check GDAL website. GRASS GIS GRASS GIS powerful raster, vector, geospatial processing engine including tools terrain ecosystem modeling, hydrology processing satellite aerial imagery. detailed installation instructions check GRASS GIS users wiki GRASS GIS website. GRASS GIS addons Copy-paste commands install required addons GRASS GIS. GNU parallel GNU parallel shell tool executing jobs parallel multiple cores. faster processing, hydrographr functions snap_to_subc_segment() extract_zonal_stat() GNU parallel implemented. information check GNU parallel website. dos2unix Windows systems uses different text file line endings Linux systems. Dos2Unix package contains commands converting line endings text file Windows Linux vice versa.","code":"# Add the Ubuntugis PPA sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable # Update the packages list sudo apt update && sudo apt upgrade # Install GDAL sudo apt install gdal-bin python3-gdal # Install GRASS GIS sudo apt-get install grass grass-core grass-dev grass-gui grass-doc sudo apt install make  # Install GRASS GIS addons export GRASSEXEC=\"grass --exec\" $GRASSEXEC  g.extension  extension=r.stream.distance $GRASSEXEC  g.extension  extension=r.stream.order $GRASSEXEC  g.extension  extension=r.stream.snap $GRASSEXEC  g.extension  extension=r.stream.basins # Download the latest version of GNU parallel  wget http://ftp.gnu.org/gnu/parallel/parallel-latest.tar.bz2  # Unzip the the .tar file and create a new folder parallel-yyyymmdd sudo tar xjf parallel-latest.tar.bz2 # Check folders and files in the directory and see the date of  # latest version e.g. parallel-20221122 ls # Move to the new created folder parallel-yyyymmdd cd parallel-20221122  sudo ./configure && make sudo make install parallel --citation  #> Academic tradition requires you to cite works you base your article on. #> If you use programs that use GNU Parallel to process data for an article in a #> scientific publication, please cite: #>  #> @software{tange_2022_7347980, #>       author       = {Tange, Ole}, #>       title        = {GNU Parallel 20221122 ('Херсо́н')}, #>       month        = Nov, #>       year         = 2022, #>       note         = {{GNU Parallel is a general parallelizer to run #>                        multiple serial command line programs in parallel #>                        without changing them.}}, #>       publisher    = {Zenodo}, #>       doi          = {10.5281/zenodo.7347980}, #>       url          = {https://doi.org/10.5281/zenodo.7347980} #> }  #> (Feel free to use \\nocite{tange_2022_7347980})  #> This helps funding further development; AND IT WON'T COST YOU A CENT. #> If you pay 10000 EUR you should feel free to use GNU Parallel without citing.  #> More about funding GNU Parallel and the citation notice: #> https://lists.gnu.org/archive/html/parallel/2013-11/msg00006.html #> https://www.gnu.org/software/parallel/parallel_design.html#citation-notice #> https://git.savannah.gnu.org/cgit/parallel.git/tree/doc/citation-notice-faq.txt  #> If you send a copy of your published article to tange@gnu.org, it will be #> mentioned in the release notes of next version of GNU Parallel. #>  #> Type: 'will cite' and press enter.  will cite  #> Thank you for your support: You are the reason why there is funding to #> continue maintaining GNU Parallel. On behalf of future versions of #> GNU Parallel, which would not exist without your support:  #>  THANK YOU SO MUCH  #> It is really appreciated. The citation notice is now silenced. # Install dos2unix sudo apt install -y dos2unix"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Maria Üblacker. Author, maintainer. Afroditi Grigoropoulou. Author. Jaime Garcia Marquez. Author. Yusdiel Torres Cambas. Author. Christoph Schürz. Author. Mathieu Floury. Author. Thomas Tomiczek. Author. Vanessa Bremerich. Author. Giuseppe Amatulli. Author. Sami Domisch. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Üblacker M, Grigoropoulou , Garcia Marquez J, Torres Cambas Y, Schürz C, Floury M, Tomiczek T, Bremerich V, Amatulli G, Domisch S (2023). hydrographr: Scalable Hydrographic Data Processing R. R package version 1.0.5, https://glowabio.github.io/hydrographr/.","code":"@Manual{,   title = {hydrographr: Scalable Hydrographic Data Processing in R},   author = {Maria Üblacker and Afroditi Grigoropoulou and Jaime {Garcia Marquez} and Yusdiel {Torres Cambas} and Christoph Schürz and Mathieu Floury and Thomas Tomiczek and Vanessa Bremerich and Giuseppe Amatulli and Sami Domisch},   year = {2023},   note = {R package version 1.0.5},   url = {https://glowabio.github.io/hydrographr/}, }"},{"path":"/index.html","id":"hydrographr-","dir":"","previous_headings":"","what":"Scalable Hydrographic Data Processing in R","title":"Scalable Hydrographic Data Processing in R","text":"hydrographr provides collection R function wrappers GDAL GRASS-GIS functions efficiently work Hydrography90m spatial biodiversity data. easy--use functions process large raster vector data directly disk parallel, memory R get overloaded. allows creating scalable data processing analysis workflows R, even though data processed directly R. add functions vignette time, invite users test package. Please notify us possible issues, bugs feature requests issues tab top page.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Scalable Hydrographic Data Processing in R","text":"Please see installation guide required tools https://glowabio.github.io/hydrographr/articles/hydrographr.html. Afterwards, use following lines install package R: pdf manual hydrographr package can downloaded . thank NFDI4Biodiversity NFDI4Earth providing funding helped us getting hydrographr package together!","code":"install.packages(\"remotes\") remotes::install_github(\"glowabio/hydrographr\") library(hydrographr)"},{"path":"/reference/check_tiles_filesize.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function that checks the size of single files before downloading.\nIt is called and inherits arguments by the function 'download_tiles()' — check_tiles_filesize","title":"Internal function that checks the size of single files before downloading.\nIt is called and inherits arguments by the function 'download_tiles()' — check_tiles_filesize","text":"Internal function checks size single files downloading. called inherits arguments function 'download_tiles()'","code":""},{"path":"/reference/check_tiles_filesize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function that checks the size of single files before downloading.\nIt is called and inherits arguments by the function 'download_tiles()' — check_tiles_filesize","text":"","code":"check_tiles_filesize(   variable,   file_format = \"tif\",   tile_id = NULL,   reg_unit_id = NULL,   global = FALSE,   h90m_varnames,   h90m_tile_id,   h90m_file_formats,   file_size_table_sep )"},{"path":"/reference/check_tiles_filesize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function that checks the size of single files before downloading.\nIt is called and inherits arguments by the function 'download_tiles()' — check_tiles_filesize","text":"variable character vector variable names. file_format character. Format requested file (\"tif\" \"gpkg\"). tile_id character. ID requested tile regional unit. global logical. TRUE, global extent file downloaded. Default FALSE. h90m_varnames character vector. valid names hydrography90m files available download, (inherited 'download_tiles()'). h90m_tile_id character vector. valid IDs hydrography90m. regular tiles available download (inherited 'download_tiles()'). h90m_file_formats character vector. valid file types files available download (inherited 'download_tiles()'). file_size_table_sep data.frame. Lookup table including file names sizes (inherited 'download_tiles()').","code":""},{"path":"/reference/check_wsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if WSL and Ubuntu is installed on Windows — check_wsl","title":"Check if WSL and Ubuntu is installed on Windows — check_wsl","text":"Check WSL Ubuntu installed Windows","code":""},{"path":"/reference/check_wsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if WSL and Ubuntu is installed on Windows — check_wsl","text":"","code":"check_wsl()"},{"path":"/reference/crop_to_extent.html","id":null,"dir":"Reference","previous_headings":"","what":"Crop raster to extent — crop_to_extent","title":"Crop raster to extent — crop_to_extent","text":"function crops input raster layer directly disk, .e. input layer need loaded R. raster .tif cropped polygon border line vector layer (cutline source) provided, otherwise bounding box provided (xmin, ymin, xmax, ymax coordinates spatial object extract bounding box), raster cropped extent bounding box. least cutline source (vector_layer) bounding box (bounding_box) provided. output always written disk, can optionally loaded R SpatRaster (terra package) object (using read = TRUE).","code":""},{"path":"/reference/crop_to_extent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Crop raster to extent — crop_to_extent","text":"","code":"crop_to_extent(   raster_layer,   vector_layer = NULL,   bounding_box = NULL,   out_dir,   file_name,   read = TRUE,   quiet = TRUE )"},{"path":"/reference/crop_to_extent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crop raster to extent — crop_to_extent","text":"raster_layer character. Full path input raster .tif layer. vector_layer character. Full path vector layer used cutline data source (similar mask operation). bounding_box numeric vector coordinates corners bounding box (xmin, ymin, xmax, ymax), SpatRaster, SpatVector, spatial object. out_dir character. directory output stored. file_name character. Name cropped output raster .tif file. read logical. TRUE, cropped raster .tif layer gets read R. FALSE, layer stored disk. Default TRUE. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/crop_to_extent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Crop raster to extent — crop_to_extent","text":"function returns always .tif raster file written disk. Optionally, SpatRaster (terra object) can loaded R read = TRUE.","code":""},{"path":"/reference/crop_to_extent.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Crop raster to extent — crop_to_extent","text":"Yusdiel Torres-Cambas","code":""},{"path":"/reference/crop_to_extent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Crop raster to extent — crop_to_extent","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Define full path to the input raster .tif layer ans vector layer spi_raster <- paste0(my_directory, \"/hydrography90m_test_data\",                      \"/spi_1264942.tif\") basin_vector <- paste0(my_directory, \"/hydrography90m_test_data\",                       \"/basin_59.gpkg\")  # Crop the Stream Power Index to the basin spi_basin <- crop_to_extent(raster_layer = spi_raster,                             vector_layer = basin_vector,                             out_dir = my_directory,                             file_name = \"spi_basin_cropped.tif\",                             read = TRUE)"},{"path":"/reference/download_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download test data — download_test_data","title":"Download test data — download_test_data","text":"Download test data package, includes Hydrography90m species point observation data small geographic extent, test functions. test data available https://drive.google.com/file/d/1kYNWXmtVm6X7MZLISOePGpvxB1pk1scD/view?usp=share_link can automatically downloaded unzipped function desired path.","code":""},{"path":"/reference/download_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download test data — download_test_data","text":"","code":"download_test_data(download_dir = \".\")"},{"path":"/reference/download_test_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download test data — download_test_data","text":"download_dir character. directory files downloaded. Default location working directory.","code":""},{"path":"/reference/download_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download test data — download_test_data","text":"Downloads test data Hydrography90m dataset","code":""},{"path":"/reference/download_test_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download test data — download_test_data","text":"Amatulli, G., Garcia Marquez, J., Sethi, T., Kiesel, J., Grigoropoulou, ., Üblacker, M. M., Shen, L. Q., Domisch, S.: Hydrography90m: new high-resolution global hydrographic dataset, Earth Syst. Sci. Data, 14, 4525–4550, https://doi.org/10.5194/essd-14-4525-2022, 2022.\") Amatulli G., Garcia Marquez J., Sethi T., Kiesel J., Grigoropoulou ., Üblacker M., Shen L. & Domisch S. (2022-08-09 ). Hydrography90m: new high-resolution global hydrographic dataset. IGB Leibniz-Institute Freshwater Ecology Inland Fisheries. dataset. https://doi.org/10.18728/igb-fred-762.1","code":""},{"path":"/reference/download_test_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download test data — download_test_data","text":"Afroditi Grigoropoulou","code":""},{"path":"/reference/download_test_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download test data — download_test_data","text":"","code":"# Download the test data to the current working directory download_test_data()  # Download the data to a specific (existing) directory download_test_data(\"path/to/your/directory\")"},{"path":"/reference/download_tiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files of the Hydrography90m dataset — download_tiles","title":"Download files of the Hydrography90m dataset — download_tiles","text":"function downloads files Hydrography90m dataset, available https://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path= files stored folder architecture domain. Multiple regular tile regional unit files can requested single call function. tile regional unit IDs can obtained using functions \"get_tile_id\" \"get_regional_unit_id\" respectively.","code":""},{"path":"/reference/download_tiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files of the Hydrography90m dataset — download_tiles","text":"","code":"download_tiles(   variable,   file_format = \"tif\",   tile_id = NULL,   reg_unit_id = NULL,   global = FALSE,   download_dir = \".\" )"},{"path":"/reference/download_tiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files of the Hydrography90m dataset — download_tiles","text":"variable character vector variable names. file_format character. Format requested file (\"tif\" \"gpkg\"). tile_id character vector. IDs requested tiles. reg_unit_id character vector. IDs requested regional units. global logical. TRUE, global extent file downloaded. Default FALSE. download_dir character. directory files downloaded. Default working directory.","code":""},{"path":"/reference/download_tiles.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download files of the Hydrography90m dataset — download_tiles","text":"Amatulli G., Garcia Marquez J., Sethi T., Kiesel J., Grigoropoulou ., Üblacker M., Shen L. & Domisch S. (2022-08-09 ) Hydrography90m: new high-resolution global hydrographic dataset. IGB Leibniz-Institute Freshwater Ecology Inland Fisheries. dataset. https://doi.org/10.18728/igb-fred-762.1","code":""},{"path":"/reference/download_tiles.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Download files of the Hydrography90m dataset — download_tiles","text":"Afroditi Grigoropoulou","code":""},{"path":"/reference/download_tiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download files of the Hydrography90m dataset — download_tiles","text":"","code":"# Download data for two variables in three regular tiles # to the current working directory download_tiles(variable = c(\"sti\", \"stream_dist_up_farth\"),                file_format = \"tif\",                tile_id = c(\"h00v02\",\"h16v02\", \"h16v04\"))  # Download the global .tif layer for the variable \"direction\" # into the temporary R folder or define a different directory # Define directory my_directory <- tempdir() # Download layer download_tiles(variable = \"direction\",                file_format = \"tif\",                global = TRUE,                download_dir = my_directory)"},{"path":"/reference/download_tiles_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function that downloads a single file from\nhttps://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path=\nGDrive folder.\nIt is called and inherits arguments by the function 'download_tiles()'. — download_tiles_base","title":"Internal function that downloads a single file from\nhttps://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path=\nGDrive folder.\nIt is called and inherits arguments by the function 'download_tiles()'. — download_tiles_base","text":"Internal function downloads single file https://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path= GDrive folder. called inherits arguments function 'download_tiles()'.","code":""},{"path":"/reference/download_tiles_base.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function that downloads a single file from\nhttps://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path=\nGDrive folder.\nIt is called and inherits arguments by the function 'download_tiles()'. — download_tiles_base","text":"","code":"download_tiles_base(   variable,   file_format = \"tif\",   tile_id = NULL,   global = FALSE,   download_dir = \".\",   file_size_table_sep = NULL,   server_url = NULL )"},{"path":"/reference/download_tiles_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function that downloads a single file from\nhttps://public.igb-berlin.de/index.php/s/agciopgzXjWswF4?path=\nGDrive folder.\nIt is called and inherits arguments by the function 'download_tiles()'. — download_tiles_base","text":"variable character vector variable names. file_format character. Format requested file (\"tif\" \"gpkg\"). tile_id character. ID requested tile regional unit. global logical. TRUE, global extent file downloaded. Default FALSE. download_dir character. directory files downloaded. Default working directory. file_size_table_sep data.frame. Lookup table including file names sizes (inherited 'download_tiles()'). server_url character. url home download folder either Nimbus GDrive (inherited 'download_tiles()').","code":""},{"path":"/reference/extract_from_gpkg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract values from the stream order .gpkg files. — extract_from_gpkg","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"function reads attribute table stream network GeoPackage file (.gpkg) stored disk extracts data one () input sub-catchment (.e. stream segment) IDs. output data.table, output loaded R.","code":""},{"path":"/reference/extract_from_gpkg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"","code":"extract_from_gpkg(   data_dir,   subc_id,   subc_layer,   var_layer,   out_dir = NULL,   file_name = NULL,   n_cores = NULL,   quiet = TRUE )"},{"path":"/reference/extract_from_gpkg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"data_dir character. Path directory containing input data. subc_id numeric vector sub-catchment IDs \"\". \"\", attribute table extracted stream segments input .gpkg layer. stream segment IDs sub-catchment IDs. vector sub-catchment IDs can acquired extract_ids() function, sub-setting resulting data.frame. subc_layer character. Full path sub-catchment ID .tif layer var_layer character vector .gpkg files disk, e.g. \"order_vect_point_h18v04.gpkg\". out_dir character. directory output stored. out_dir specified, attribute tables stored .csv files location, named input variable vector files (e.g. \"/path//stats_order_vect_point_h18v04.csv\"). NULL, output loaded R stored disk. file_name character. Name .csv file output table stored. out_dir also specified purpose. n_cores numeric. Number cores used parallelization, case multiple .gpkg files provided var_layer. NULL, available cores - 1 used. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/extract_from_gpkg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"https://grass.osgeo.org/grass82/manuals/v..ogr.html","code":""},{"path":"/reference/extract_from_gpkg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"Afroditi Grigoropoulou, Jaime Garcia Marquez, Maria M. Üblacker","code":""},{"path":"/reference/extract_from_gpkg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract values from the stream order .gpkg files. — extract_from_gpkg","text":"","code":"# Download test data into temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Define path to the directory containing all input data test_data <- paste0(my_directory, \"/hydrography90m_test_data\")  # Define sub-catchment ID layer subc_raster <- paste0(my_directory, \"/hydrography90m_test_data\",                   \"/subcatchment_1264942.tif\")  # Extract the attribute table of the file order_vect_59.gpkg for all the # sub-catchment IDs of the subcatchment_1264942.tif raster layer attribute_table <- extract_from_gpkg(data_dir = test_data,                                      subc_id = \"all\",                                      subc_layer = subc_raster,                                      var_layer = \"order_vect_59.gpkg\",                                      n_cores = 1)  # Show the output table attribute_table"},{"path":"/reference/extract_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract sub-catchment and/or basin IDs — extract_ids","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"Extracts ID value basin /sub-catchment raster layer given point location.","code":""},{"path":"/reference/extract_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"","code":"extract_ids(   data,   lon,   lat,   id = NULL,   basin_layer = NULL,   subc_layer = NULL,   quiet = TRUE )"},{"path":"/reference/extract_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"data data.frame data.table lat/lon coordinates WGS84. lon character. name column longitude coordinates. lat character. name column latitude coordinates. id character. name column containing unique IDs row \"data\" (e.g., occurrence site IDs). basin_layer character. Full path basin ID .tif layer. subc_layer character. Full path sub-catchment ID .tif layer. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/extract_ids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"extraction value given point location basin /sub-catchment raster layer Hydrography90m dataset, GDAL function 'gdallocationinfo' used. point locations defined coordinates WGS84 reference system. function can also used extract value given raster layer WGS84 projection, e.g. environmental information stored input raster file.","code":""},{"path":"/reference/extract_ids.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"Duplicated rows removed.","code":""},{"path":"/reference/extract_ids.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"https://gdal.org/programs/gdallocationinfo.html","code":""},{"path":"/reference/extract_ids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"Afroditi Grigoropoulou, Maria Üblacker","code":""},{"path":"/reference/extract_ids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract sub-catchment and/or basin IDs — extract_ids","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load occurrence data species_occurrence <- read.table(paste0(my_directory,                                         \"/hydrography90m_test_data\",                                         \"/spdata_1264942.txt\"),                                  header = TRUE)  # Define full path to the basin and sub-catchments raster layer basin_raster <- paste0(my_directory,                      \"/hydrography90m_test_data/basin_1264942.tif\") subc_raster <- paste0(my_directory,                     \"/hydrography90m_test_data/basin_1264942.tif\")  # Extract basin and sub-catchment IDs from the Hydrography90m layers hydrography90m_ids <- extract_ids(data = species_occurrence,                                   lon = \"longitude\",                                   lat = \"latitude\",                                   id = \"occurrence_id\",                                   subc_layer = subc_raster,                                   basin_layer = basin_raster)  # Show the output table hydrography90m_ids"},{"path":"/reference/extract_zonal_stat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate zonal statistics — extract_zonal_stat","title":"Calculate zonal statistics — extract_zonal_stat","text":"Calculate zonal statistics based one environmental variable raster .tif layers. function can used aggregate data across set () sub-catchments. sub-catchment raster (.tif) input file stored disk. output data.table loaded R.","code":""},{"path":"/reference/extract_zonal_stat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate zonal statistics — extract_zonal_stat","text":"","code":"extract_zonal_stat(   data_dir,   subc_id,   subc_layer,   var_layer,   out_dir = NULL,   file_name = NULL,   n_cores = NULL,   quiet = TRUE )"},{"path":"/reference/extract_zonal_stat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate zonal statistics — extract_zonal_stat","text":"data_dir character. Path directory containing input data. subc_id Vector sub-catchment IDs \"\". \"\", zonal statistics calculated sub-catchments given sub-catchment raster layer. vector sub-catchment IDs can acquired extract_ids() function, sub-setting resulting data.frame. subc_layer character. Full path sub-catchment ID .tif layer. var_layer character vector variable raster layers disk, e.g. \"slope_grad_dw_cel_h00v00.tif\". Variable names remain intact file names, even file processing, .e., slope_grad_dw_cel appear file name. files cropped extent sub-catchment layer speed computation. out_dir character. directory output stored. out_dir file_name specified, output table stored .csv file location. NULL, output loaded R stored disk. file_name character. Name .csv file output table stored. out_dir also specified purpose. n_cores numeric. Number cores used parallelization, case multiple .tif files provided var_layer. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/extract_zonal_stat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate zonal statistics — extract_zonal_stat","text":"https://grass.osgeo.org/grass82/manuals/r.univar.html","code":""},{"path":[]},{"path":"/reference/extract_zonal_stat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate zonal statistics — extract_zonal_stat","text":"Afroditi Grigoropoulou, Jaime Garcia Marquez, Maria M. Üblacker","code":""},{"path":"/reference/extract_zonal_stat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate zonal statistics — extract_zonal_stat","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Define full path to the sub-catchment ID .tif layer subc_raster <-  paste0(my_directory, \"/hydrography90m_test_data\",                        \"/subcatchment_1264942.tif\")  # Define the directory where the output will be stored output_folder <- paste0(my_directory, \"/hydrography90m_test_data/output\") # Create output folder if it doesn't exist if(!dir.exists(output_folder)) dir.create(output_folder)  # Calculate the zonal statistics for all sub-catchments for two variables stat <- extract_zonal_stat(data_dir = paste0(my_directory,                                              \"/hydrography90m_test_data\"),                            subc_id = c(513837216, 513841103,                                        513850467, 513868394,                                        513870312),                            subc_layer = subc_raster,                            var_layer = c(\"spi_1264942.tif\",                                          \"sti_1264942.tif\"),                            out_dir = output_folder,                            file_name = \"zonal_statistics.csv\",                            n_cores = 2) # Show output table stat"},{"path":"/reference/fix_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix path for WSL on Windows — fix_path","title":"Fix path for WSL on Windows — fix_path","text":"Fix path WSL Windows","code":""},{"path":"/reference/fix_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix path for WSL on Windows — fix_path","text":"","code":"fix_path(path)"},{"path":"/reference/fix_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix path for WSL on Windows — fix_path","text":"path Full Windows path.","code":""},{"path":"/reference/get_catchment_graph.html","id":null,"dir":"Reference","previous_headings":"","what":"Get catchment from graph — get_catchment_graph","title":"Get catchment from graph — get_catchment_graph","text":"Subset network graph extracting upstream, downstream entire catchment, one multiple stream segments. function return either one data.tables graph objects input stream segment. Note stream segment sub-catchment IDs identical, consistency, use term \"subc_id\". switching mode either \"\", \"\" \"\", upstream, downstream connected segments returned.","code":""},{"path":"/reference/get_catchment_graph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get catchment from graph — get_catchment_graph","text":"","code":"get_catchment_graph(   g,   subc_id = NULL,   outlet = FALSE,   mode = NULL,   as_graph = FALSE,   n_cores = 1,   max_size = 1500 )"},{"path":"/reference/get_catchment_graph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get catchment from graph — get_catchment_graph","text":"g igraph object. directed graph. subc_id numeric vector single multiple IDs, e.g (c(ID1, ID2, ID3, ...). sub-catchment (equivalent stream segment) IDs delineate upstream drainage area. empty, outlets used sub-catchment IDs (outlet = TRUE). Note can browse entire network online https://geo.igb-berlin.de/maps/351/view left hand side, select \"Stream segment ID\"  layer click map get ID. Optional. outlet logical. TRUE, outlets given network graph used additional input subc_ids. Outlets identified internally stream segments downstream connected segment. Default FALSE. mode character. One \"\", \"\" \"\". \"\" returns upstream catchment, \"\" returns downstream catchment (catchments reachable given input segment), \"\" returns . as_graph logical. TRUE, output new graph list new graphs original attributes. FALSE, output  new data.table list data.tables. List objects named subc_ids. Default FALSE. n_cores numeric. Number cores used parallelization case multiple stream segments / outlets. Default 1. Currently, parallelization process requires copying data core. case graph large, many segments used input, setting n_cores higher value can speed computation. comes however cost possible RAM limitations even slower processing since large data copied core. Hence consider testing n_cores = 1 first. Optional. max_size numeric. Specifies maximum size data passed parallel back-end MB. Default 1500 (1.5 GB). Consider higher value large study areas (one 20°x20° tile). Optional.","code":""},{"path":"/reference/get_catchment_graph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get catchment from graph — get_catchment_graph","text":"graph data.table reports subc_ids. case multiple input segments, results stored list.","code":""},{"path":"/reference/get_catchment_graph.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get catchment from graph — get_catchment_graph","text":"Csardi G, Nepusz T: igraph software package complex network research, InterJournal, Complex Systems 1695. 2006. https://igraph.org","code":""},{"path":"/reference/get_catchment_graph.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get catchment from graph — get_catchment_graph","text":"Sami Domisch","code":""},{"path":"/reference/get_catchment_graph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get catchment from graph — get_catchment_graph","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load stream network as a graph my_graph <- read_geopackage(gpkg = paste0(my_directory,                                          \"/hydrography90m_test_data\",                                          \"/order_vect_59.gpkg\"),                            import_as = \"graph\")  # Pick a random subc_id subc_id = \"513855877\" # Get the upstream catchment as a graph g_up <- get_catchment_graph(g = my_graph, subc_id = subc_id, mode = \"in\",                             outlet = FALSE, as_graph = TRUE, n_cores = 1)  # Get the downstream segments as a data.table, g_down <- get_catchment_graph(g = my_graph, subc_id = subc_id, mode = \"out\",                               outlet = FALSE, as_graph = FALSE, n_cores = 1)  # Get the catchments of all outlets in the study area as a graph g_all <- get_catchment_graph(g = my_graph, mode = \"in\", outlet = TRUE,                              as_graph = TRUE, n_cores = 1)"},{"path":"/reference/get_os.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify the operating system.\nThe function was written by Will Lowe and was copied from here:\nhttps://conjugateprior.org/2015/06/identifying-the-os-from-r/ — get_os","title":"Identify the operating system.\nThe function was written by Will Lowe and was copied from here:\nhttps://conjugateprior.org/2015/06/identifying-the-os-from-r/ — get_os","text":"Identify operating system. function written Lowe copied : https://conjugateprior.org/2015/06/identifying--os--r/","code":""},{"path":"/reference/get_os.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify the operating system.\nThe function was written by Will Lowe and was copied from here:\nhttps://conjugateprior.org/2015/06/identifying-the-os-from-r/ — get_os","text":"","code":"get_os()"},{"path":"/reference/get_regional_unit_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Hydrography90m regional unit IDs — get_regional_unit_id","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"Identifies IDs regional units within Hydrography90m data input points located. IDs required download data using download_tiles(). Input point data frame.","code":""},{"path":"/reference/get_regional_unit_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"","code":"get_regional_unit_id(data, lon, lat, quiet = TRUE)"},{"path":"/reference/get_regional_unit_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"data data.frame data.table lat/lon coordinates WGS84. lon character. name column longitude coordinates. lat character. name column latitude coordinates.","code":""},{"path":"/reference/get_regional_unit_id.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"https://gdal.org/programs/gdallocationinfo.html","code":""},{"path":"/reference/get_regional_unit_id.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"Afroditi Grigoropoulou","code":""},{"path":"/reference/get_regional_unit_id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Hydrography90m regional unit IDs — get_regional_unit_id","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Read the species data species_occurence <- read.table(paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/spdata_1264942.txt\"),                               header = TRUE)  # Get the regional unit ID get_regional_unit_id(species_occurence, lon = \"longitude\",                     lat = \"latitude\")"},{"path":"/reference/get_segment_neighbours.html","id":null,"dir":"Reference","previous_headings":"","what":"Get stream segment neighbours — get_segment_neighbours","title":"Get stream segment neighbours — get_segment_neighbours","text":"segment, reports upstream, downstream, -downstream segments connected one multiple input segments within specified neighbour order, option summarize attributes across segments. Note stream segment sub-catchment IDs identical, consistency, use term \"subc_id\". function can also used create connectivity table Marxan using var_layer=\"length\" attach_only=TRUE. resulting table reports connectivity segment, along stream length connected segments.","code":""},{"path":"/reference/get_segment_neighbours.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get stream segment neighbours — get_segment_neighbours","text":"","code":"get_segment_neighbours(   g,   subc_id = NULL,   var_layer = NULL,   stat = NULL,   attach_only = FALSE,   order = 5,   mode = \"in\",   n_cores = 1,   max_size = 1500 )"},{"path":"/reference/get_segment_neighbours.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get stream segment neighbours — get_segment_neighbours","text":"g igraph object. directed graph. subc_id numeric vector input sub-catchment IDs (=stream segment IDs) search connected segments. var_layer character vector. One attributes (variable layers) input graph reported output segment_id (\"to_stream\"). Optional. stat one functions mean, median, min, max, sd (without quotes). Aggregates (summarizes) variables neighbourhood input segment (\"stream\", e.g., average land cover next five upstream segments sub-catchments). Default NULL. attach_only logical. TRUE, selected variables attached segment without aggregation. Default FALSE. order numeric. neighbouring order igraph::ego. Order = 1 immediate neighbours input sub-catchment IDs, order = 2 order 1 plus immediate neighbours sub-catchment IDs order 1, . mode character. One \"\", \"\", \"\". \"\" returns upstream neighbouring segments, \"\" returns downstream segments, \"\" returns . n_cores numeric. Number cores used parallelization case multiple stream segments / outlets. Default 1. Currently, parallelization process requires copying data core. case graph large, many segments used input, setting n_cores higher value can speed computation. comes however cost possible RAM limitations even slower processing since large data copied core. Hence consider testing n_cores = 1 first. Optional. max_size numeric. Specifies maximum size data passed parallel back-end MB. Default 1500 (1.5 GB). Consider higher value large study areas (one 20°x20° tile). Optional.","code":""},{"path":"/reference/get_segment_neighbours.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get stream segment neighbours — get_segment_neighbours","text":"Csardi G, Nepusz T: igraph software package complex network research, InterJournal, Complex Systems 1695. 2006. https://igraph.org","code":""},{"path":"/reference/get_segment_neighbours.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get stream segment neighbours — get_segment_neighbours","text":"Sami Domisch","code":""},{"path":"/reference/get_segment_neighbours.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get stream segment neighbours — get_segment_neighbours","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load the stream network as graph my_graph <- read_geopackage(gpkg= paste0(my_directory,                                          \"/hydrography90m_test_data\",                                          \"/order_vect_59.gpkg\"),                             import_as = \"graph\")  # Get the upstream segment neighbours in the 5th order # and report the length and source elevation # for the neighbours of each input segment get_segment_neighbours(g = my_graph, subc_id = subc_id,                        order = 5, mode = \"in\", n_cores = 1,                        var_layer = c(\"length\", \"source_elev\"),                        attach_only = TRUE)  # Get the downstream segment neighbours in the 5th order # and calculate the median length and source elevation # across the neighbours of each input segment get_segment_neighbours(g = my_graph, subc_id = subc_id,                        order = 2, mode =\"out\", n_cores = 1,                        var_layer = c(\"length\", \"source_elev\"),                        stat = median)  # Get the up-and downstream segment neighbours in the 5th order # and report the median length and source elevation # for the neighbours of each input segment get_segment_neighbours(g = my_graph, subc_id = subc_id, order = 2,                        mode = \"all\", n_cores = 1,                        var_layer = c(\"length\", \"source_elev\"),                        stat = mean, attach_only = TRUE)"},{"path":"/reference/get_tile_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Hydrography90m regular tile ID — get_tile_id","title":"Get the Hydrography90m regular tile ID — get_tile_id","text":"Identifies ids tiles within Hydrography90m data given points located. IDs required download data using download_tiles(). Input point data frame.","code":""},{"path":"/reference/get_tile_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Hydrography90m regular tile ID — get_tile_id","text":"","code":"get_tile_id(data, lon, lat)"},{"path":"/reference/get_tile_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Hydrography90m regular tile ID — get_tile_id","text":"data data.frame data.table lat/lon coordinates WGS84. lon character. name column longitude coordinates. lat character. name column latitude coordinates.","code":""},{"path":"/reference/get_tile_id.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the Hydrography90m regular tile ID — get_tile_id","text":"Afroditi Grigoropoulou","code":""},{"path":"/reference/get_tile_id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Hydrography90m regular tile ID — get_tile_id","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load species occurrence data species_occurrence <- read.table(paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/spdata_1264942.txt\"),                                  header = TRUE)  # Get the tile ID get_tile_id(data = species_occurrence,             lon = \"longitude\", lat = \"latitude\")"},{"path":"/reference/get_upstream_catchment.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate upstream basin — get_upstream_catchment","title":"Calculate upstream basin — get_upstream_catchment","text":"Calculates upstream basin given point, considering point outlet.","code":""},{"path":"/reference/get_upstream_catchment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate upstream basin — get_upstream_catchment","text":"","code":"get_upstream_catchment(   data,   id,   lon,   lat,   direction_layer = NULL,   out_dir = NULL,   n_cores = NULL,   quiet = TRUE )"},{"path":"/reference/get_upstream_catchment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate upstream basin — get_upstream_catchment","text":"data data.frame data.table lat/lon coordinates WGS84, snapped stream network. snapping can done using function 'snap_to_network'. id character. name column containing unique IDs row \"data\" (e.g., occurrence site IDs). lon character. name column longitude coordinates. lat character. name column latitude coordinates. direction_layer character. Full path raster file direction variable. out_dir Full path directory output(s) stored. identify upstream catchment output file name includes site id. n_cores numeric. Number cores used parallelization. NULL, available cores - 1 used. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/get_upstream_catchment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate upstream basin — get_upstream_catchment","text":"https://grass.osgeo.org/grass82/manuals/r.water.outlet.html https://grass.osgeo.org/grass82/manuals/r.region.html","code":""},{"path":[]},{"path":"/reference/get_upstream_catchment.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate upstream basin — get_upstream_catchment","text":"Jaime Garcia Marquez, Afroditi Grigoropoulou, Maria M. Üblacker","code":""},{"path":"/reference/get_upstream_catchment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate upstream basin — get_upstream_catchment","text":"","code":"# Download test data into temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Before running the function get_upstream_catchment(), snap the points to # to the stream segment. There are multiple ways to snap the points. Here is # one example:  # Load occurrence data species_occurence <- read.table(paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/spdata_1264942.txt\"),                               header = TRUE)  # Define full path to the basin and sub-catchments raster layer basin_raster <- paste0(my_directory,                        \"/hydrography90m_test_data/basin_1264942.tif\") subc_raster <- paste0(my_directory,                       \"/hydrography90m_test_data/subcatchment_1264942.tif\")  # Define full path to the vector file of the stream network stream_vector <- paste0(my_directory,                         \"/hydrography90m_test_data/order_vect_59.gpkg\")  # Automatically extract the basin and sub-catchment IDs and # snap the data points to the stream segment snapped_coordinates <- snap_to_subc_segment(data = species_occurence,                                             lon = \"longitude\",                                             lat = \"latitude\",                                             id = \"occurrence_id\",                                             basin_layer = basin_raster,                                             subc_layer = subc_raster,                                             stream_layer = stream_vector,                                             n_cores = 2)  # Define full path to the direction .tif direction_raster <- paste0(my_directory,                            \"/hydrography90m_test_data/direction_1264942.tif\") # Define the path for the output file(s) output_folder <-  paste0(my_directory, \"/upstream_catchments\") if(!dir.exists(output_folder)) dir.create(output_folder) # Get the upstream catchment for each point location get_upstream_catchment(snapped_coordinates,                        lon = \"lon_snap\",                        lat = \"lat_snap\",                        id = \"occurrence_id\",                        direction_layer = direction_raster,                        out_dir = output_folder,                        n_cores = 2)"},{"path":"/reference/make_sh_exec.html","id":null,"dir":"Reference","previous_headings":"","what":"Make bash scripts executable — make_sh_exec","title":"Make bash scripts executable — make_sh_exec","text":"Make bash scripts executable","code":""},{"path":"/reference/make_sh_exec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make bash scripts executable — make_sh_exec","text":"","code":"make_sh_exec()"},{"path":"/reference/merge_tiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge raster or vector objects — merge_tiles","title":"Merge raster or vector objects — merge_tiles","text":"Merge multiple raster spatial vector objects disk form new raster spatial vector object larger spatial extent. directory least two raster .tif spatial vector geopackage files provided. Depending input, output .tif .gpkg file (saved out_dir). read = TRUE, output read R SpatRaster (terra package) object case .tif files, SpatVector (terra package) object case .gpkg files.","code":""},{"path":"/reference/merge_tiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge raster or vector objects — merge_tiles","text":"","code":"merge_tiles(   tile_dir,   tile_names,   out_dir,   file_name,   read = FALSE,   quiet = TRUE )"},{"path":"/reference/merge_tiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge raster or vector objects — merge_tiles","text":"tile_dir character. directory containing raster spatial vectors tiles, merged. tile_names character. names files merged, including file extension (.tif .gpkg). out_dir character. directory output stored. file_name character. Name merged output file, including file extension (.tif .gpkg). read logical. TRUE, merged layer gets read R. FALSE, layer stored disk. Default FALSE. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/merge_tiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge raster or vector objects — merge_tiles","text":".tif raster file .gpkg spatial vector object always written disk, optionally loaded R.","code":""},{"path":"/reference/merge_tiles.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Merge raster or vector objects — merge_tiles","text":"https://gdal.org/programs/gdalbuildvrt.html https://gdal.org/programs/gdal_translate.html https://gdal.org/programs/ogrmerge.html#ogrmerge https://gdal.org/programs/ogr2ogr.html","code":""},{"path":"/reference/merge_tiles.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Merge raster or vector objects — merge_tiles","text":"Thomas Tomiczek, Jaime Garcia Marquez, Afroditi Grigoropoulou","code":""},{"path":"/reference/merge_tiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge raster or vector objects — merge_tiles","text":"","code":"# Download tiles into the temporary R folder # or define a different directory my_directory <- tempdir() download_tiles(variable = \"basin\",                file_format = \"tif\",                tile_id = c(\"h22v08\",\"h22v10\"),                download_dir = my_directory)  # Define folder containing only the tiles, which should me merged tiles_folder <- paste0(my_directory, \"/r.watershed/basin_tiles20d\") # Define output folder output_folder <- paste0(my_directory, \"/merged_tiles\") # Create output folder if it doesn't exist if(!dir.exists(output_folder)) dir.create(output_folder)   # Merge tiles merged_tiles <- merge_tiles(tile_dir = tiles_folder,                             tile_names = c(\"h22v08\", \"h22v10\"),                             out_dir = output_folder,                             file_name = \"basin_merged.tif\",                             read = TRUE)"},{"path":"/reference/read_geopackage.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a GeoPackage file — read_geopackage","title":"Read a GeoPackage file — read_geopackage","text":"Reads entire, subset GeoPackage vector file disk either table (data.table), directed graph object (igraph), spatial dataframe (sf) SpatVect object (terra).","code":""},{"path":"/reference/read_geopackage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a GeoPackage file — read_geopackage","text":"","code":"read_geopackage(   gpkg,   import_as = \"data.table\",   layer_name = NULL,   subc_id = NULL,   name = \"stream\" )"},{"path":"/reference/read_geopackage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a GeoPackage file — read_geopackage","text":"gpkg character. Full path GeoPackage file. import_as character. \"data.table\", \"graph\", \"sf\", \"SpatVect\". \"data.table\" imports data data.table. \"graph\" imports layer directed graph (igraph object). option possible network layer (e.g. stream network). \"sf\" imports layer  spatial data frame (sf object). \"SpatVect\" imports layer SpatVector (terra object). Default \"data.table\". layer_name character. Name specific data layer import GeoPackage. specific data layer needs defined GeoPackage contains multiple layers. see available layers function st_layers() R package 'sf' can used. Optional. Default NULL. subc_id numeric. Vector sub-catchment (stream segment) IDs form (c(ID1, ID2, ...) spatial objects attributes GeoPackage imported. Optional. Default NULL. name character. attribute table column name stream segment (\"stream\"), sub-catchment (\"ID\"), basin (\"ID\") outlet (\"ID\") column used subsetting GeoPackage prior importing. Optional. Default \"stream\".","code":""},{"path":"/reference/read_geopackage.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Read a GeoPackage file — read_geopackage","text":"Sami Domisch, Maria M.Üblacker","code":""},{"path":"/reference/read_geopackage.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a GeoPackage file — read_geopackage","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)   # Read the stream network as a graph my_graph <- read_geopackage(gpkg = paste0(my_directory,                                           \"/hydrography90m_test_data\",                                           \"/order_vect_59.gpkg\"),                                           import_as = \"graph\")  # Read the stream network as a data.table my_dt <- read_geopackage(gpkg = paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/order_vect_59.gpkg\"))  # Read the stream network as a data.table for specific IDs my_dt <- read_geopackage(gpkg = paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/order_vect_59.gpkg\"),                                        subc_id = c(513833203, 513833594))  # Read the sub-catchments as a SF-object my_sf <- read_geopackage(gpkg = paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/sub_catchment_59.gpkg\"),                                        import_as = \"sf\",                                        layer_name = \"sub_catchment\")  # Read a subset of sub-catchments as a SF-object my_sf <- read_geopackage(gpkg = paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/sub_catchment_59.gpkg\"),                                        import_as = \"sf\",                                        subc_id = c(513833203, 513833594),                                        name = \"ID\")  # Read the basin as SpatVect object my_sv <- read_geopackage(gpkg = paste0(my_directory,                                        \"/hydrography90m_test_data\",                                        \"/basin_59.gpkg\"),                                        import_as = \"SpatVect\")"},{"path":"/reference/reclass_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Reclassify an integer raster layer — reclass_raster","title":"Reclassify an integer raster layer — reclass_raster","text":"Reclassifies integer raster .tif layer using r.reclass function GRASS GIS. reclassify raster layer present raster values new raster values defined. input raster layer floating point values, multiply input data factor (e.g. 1000) achieve integer values, otherwise GRASS GIS r.reclass round raster values next integer always desired.","code":""},{"path":"/reference/reclass_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reclassify an integer raster layer — reclass_raster","text":"","code":"reclass_raster(   data,   rast_val,   new_val,   raster_layer,   recl_layer,   read = TRUE,   no_data = -9999,   type = \"Int32\",   compress = \"DEFLATE\",   quiet = TRUE )"},{"path":"/reference/reclass_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reclassify an integer raster layer — reclass_raster","text":"data data.frame data.table present new raster values. rast_val character. name column present raster values. new_val character. name column new raster values. raster_layer Full path input raster .tif layer. recl_layer character. Full path output .tif layer reclassified raster file. read logical. TRUE, reclassified raster .tif layer gets read R SpatRaster (terra object). FALSE, layer stored disk. Default TRUE. no_data numeric. no_data value new .tif layer. Default -9999. type character. Data type; Options Byte, Int16, UInt16, Int32, UInt32,CInt16, CInt32. Default Int32. compress Compression type: DEFLATE LZW. Default DEFLATE.","code":""},{"path":"/reference/reclass_raster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reclassify an integer raster layer — reclass_raster","text":"https://grass.osgeo.org/grass82/manuals/r.reclass.html","code":""},{"path":"/reference/reclass_raster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reclassify an integer raster layer — reclass_raster","text":"Maria M. Üblacker","code":""},{"path":"/reference/reclass_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reclassify an integer raster layer — reclass_raster","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Read the stream order for each sub-catchment as a data.table my_dt <- read_geopackage(gpkg= paste0(my_directory,                                          \"/hydrography90m_test_data\",                                          \"/order_vect_59.gpkg\"),                          import_as = \"data.table\")   # Select the stream segment ID and and the Strahler stream order str_ord <- my_dt[,c(\"stream\", \"strahler\")]  # Define input and output raster layer stream_raster <- paste0(my_directory,                         \"/hydrography90m_test_data/stream_1264942.tif\")  recl_raster <- paste0(my_directory,                       \"/hydrography90m_test_data/reclassified_raster.tif\")  # Reclassify the stream network to obtain the Strahler stream order raster str_ord_rast <- reclass_raster(data = str_ord,                                rast_val = \"stream\",                                new_val = \"strahler\",                                raster_layer = stream_raster,                                recl_layer = recl_raster)"},{"path":"/reference/report_no_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Report NoData value — report_no_data","title":"Report NoData value — report_no_data","text":"function reports defined NoData value raster layer. NoData value raster layer represents absence data. computations NoData value can treated different ways. Either NoData value reported Nodata value ignored value computed available values specified location.","code":""},{"path":"/reference/report_no_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report NoData value — report_no_data","text":"","code":"report_no_data(data_dir, var_layer, n_cores = NULL)"},{"path":"/reference/report_no_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report NoData value — report_no_data","text":"data_dir character. Path directory containing input data. var_layer character vector variable raster layers disk, e.g. \"slope_grad_dw_cel_h00v00.tif\". n_cores numeric. Number cores used parallelization, case multiple .tif files provided var_layer.","code":""},{"path":"/reference/report_no_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Report NoData value — report_no_data","text":"https://gdal.org/programs/gdalinfo.html","code":""},{"path":"/reference/report_no_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Report NoData value — report_no_data","text":"Afroditi Grigoropoulou, Maria M. Üblacker","code":""},{"path":"/reference/report_no_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report NoData value — report_no_data","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Report the NoData value report_no_data(data_dir = paste0(my_directory, \"/hydrography90m_test_data\"),                var_layer = c(\"subcatchment_1264942.tif\", \"flow_1264942.tif\",                              \"spi_1264942.tif\"),                n_core = 2)"},{"path":"/reference/set_no_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Set no data value — set_no_data","title":"Set no data value — set_no_data","text":"Change set NoData value raster layer. change happens -place, meaning original file overwritten disk.","code":""},{"path":"/reference/set_no_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set no data value — set_no_data","text":"","code":"set_no_data(data_dir, var_layer, no_data, quiet = TRUE)"},{"path":"/reference/set_no_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set no data value — set_no_data","text":"data_dir character. Path directory containing input data. var_layer character vector variable layers disk, e.g. c(\"sti_h16v02.tif\", \"slope_grad_dw_cel_h00v00.tif\"). original files overwritten. no_data numeric. desired NoData value. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/set_no_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set no data value — set_no_data","text":"https://gdal.org/programs/gdal_edit.html","code":""},{"path":"/reference/set_no_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set no data value — set_no_data","text":"Afroditi Grigoropoulou, Maria M. Üblacker","code":""},{"path":"/reference/set_no_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set no data value — set_no_data","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Define no data value set_no_data(data_dir = paste0(my_directory, \"/hydrography90m_test_data\"),             var_layer = \"cti_1264942.tif\",             no_data = -9999)"},{"path":"/reference/snap_to_network.html","id":null,"dir":"Reference","previous_headings":"","what":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"Snap points next stream segment within defined radius minimum flow accumulation.","code":""},{"path":"/reference/snap_to_network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"","code":"snap_to_network(   data,   lon,   lat,   id,   stream_layer,   accu_layer = NULL,   method = \"distance\",   distance = 500,   accumulation = 0.5,   quiet = TRUE )"},{"path":"/reference/snap_to_network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"data data.frame data.table lat/lon coordinates WGS84. lon character. name column longitude coordinates. lat character. name column latitude coordinates. id character. name column containing unique IDs row \"data\" (e.g., occurrence site IDs). stream_layer character. Full path stream network .gpkg file accu_layer character. Full path flow accumulation .tif file. Needed point snapped next stream segment accumulation value higher flow accumulation threshold (set 'accumulation'). prevents points snapped small stream tributaries. method character. One \"distance\", \"accumulation\", \"\". Defines points snapped using distance flow accumulation (see \"Details\" information). method set \"\" output contain new coordinates calculations. Default \"distance\". distance numeric. Maximum radius meters. points snapped next stream within radius. Default 500. accumulation numeric. Minimum flow accumulation. Points snapped next stream flow accumulation equal higher given value. Default 0.5. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/snap_to_network.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"function makes use r.stream.snap command available GRASS GIS simultaneously number points stream network. distance threshold can specified points snapped stream segment within distance radius. However, avoid snapping small tributaries, accumulation threshold can used snapping occurs stream segment equal higher accumulation threshold within given distance radius.","code":""},{"path":"/reference/snap_to_network.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"Duplicated rows removed.","code":""},{"path":"/reference/snap_to_network.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"https://grass.osgeo.org/grass78/manuals/addons/r.stream.snap.html","code":""},{"path":"/reference/snap_to_network.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"Maria M. Üblacker, Jaime Garcia Marquez","code":""},{"path":"/reference/snap_to_network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Snap points to stream segment based on distance or flow accumulation — snap_to_network","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load occurrence data species_occurence <- read.table(paste0(my_directory,                             \"/hydrography90m_test_data/spdata_1264942.txt\"),                               header = TRUE)  # Define full path to flow accumulation stream_rast <- paste0(my_directory,                      \"/hydrography90m_test_data/stream_1264942.tif\") flow_rast <- paste0(my_directory,                      \"/hydrography90m_test_data/flow_1264942.tif\")  # To calculate the new (snapped) coordinates for a radius and a flow snapped_coordinates <- snap_to_network(data = species_occurrence,                                        lon = \"longitude\",                                        lat = \"latitude\",                                        id = \"occurrence_id\",                                        stream_layer = stream_vect,                                        accu_layer = flow_rast,                                        method = \"both\",                                        distance = 300,                                        accumulation = 0.8)  # Show head of output table head(snapped_coordinates)"},{"path":"/reference/snap_to_subc_segment.html","id":null,"dir":"Reference","previous_headings":"","what":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"Snaps data points stream segment sub-catchment data point located.","code":""},{"path":"/reference/snap_to_subc_segment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"","code":"snap_to_subc_segment(   data,   lon,   lat,   id,   basin_id = NULL,   subc_id = NULL,   basin_layer,   subc_layer,   stream_layer,   n_cores = 1,   quiet = TRUE )"},{"path":"/reference/snap_to_subc_segment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"data data.frame data.table lat/lon coordinates WGS84. lon character. name column longitude coordinates. lat character. name column latitude coordinates. id character. name column containing unique IDs row \"data\" (e.g., occurrence site IDs). basin_id character. name column basin IDs. NULL, basin IDs extracted automatically. Default NULL subc_id character. name column sub-catchment IDs. NULL, sub-catchment IDs extracted automatically. Default NULL. basin_layer character. Full path basin ID .tif layer. subc_layer character. Full path sub-catchment ID .tif layer. stream_layer character. Full path stream network .gpkg file. n_cores numeric. Number cores used parallelization. Default 1. quiet logical. FALSE, standard output printed. Default TRUE.","code":""},{"path":"/reference/snap_to_subc_segment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"function uses network preparation maintenance module GRASS GIS (v.net), connect vector lines map (stream network) points map (occurrence/sampling points). masking stream segment sub-catchment target point located, connect operation snaps point stream segment using distance threshold. threshold automatically calculated longest distance two points within sub-catchment. way snapping always take place.operation creates new node vector line (.e. stream segment) new snapped coordinates can extracted.","code":""},{"path":"/reference/snap_to_subc_segment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"https://grass.osgeo.org/grass82/manuals/v.net.html","code":""},{"path":[]},{"path":"/reference/snap_to_subc_segment.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"Jaime Garcia Marquez, Maria M. Üblacker","code":""},{"path":"/reference/snap_to_subc_segment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Snap points to stream segment within the sub-catchment — snap_to_subc_segment","text":"","code":"# Download test data into the temporary R folder # or define a different directory my_directory <- tempdir() download_test_data(my_directory)  # Load occurrence data species_occurence <- read.table(paste0(my_directory,                             \"/hydrography90m_test_data/spdata_1264942.txt\"),                               header = TRUE) basin_rast <- paste0(my_directory,                      \"/hydrography90m_test_data/basin_1264942.tif\") subc_rast <- paste0(my_directory,                     \"/hydrography90m_test_data/subcatchment_1264942.tif\")  # Define full path to the vector file of the stream network stream_vect <- paste0(my_directory,                       \"/hydrography90m_test_data/order_vect_59.gpkg\")  hydrography90m_ids <- extract_ids(data = species_occurence,                                   lon = \"longitude\",                                   lat = \"latitude\",                                   id = \"occurrence_id\",                                   subc_layer = subc_rast,                                   basin_layer = basin_rast)  # Snap data points to the stream segment of the provided sub-catchment ID snapped_coordinates <- snap_to_subc_segment(data = hydrography90m_ids,                                             lon = \"longitude\",                                             lat = \"latitude\",                                             id = \"occurrence_id\",                                             basin_id = \"basin_id\",                                             subc_id = \"subcatchment_id\",                                             basin_layer = basin_rast,                                             subc_layer = subc_rast,                                             stream_layer = stream_vect,                                             n_cores = 2) # Show head of output table head(snapped_coordinates)  # OR # Automatically extract the basin and sub-catchment IDs and # snap the data points to the stream segment snapped_coordinates <- snap_to_subc_segment(data = species_occurence,                                             lon = \"longitude\",                                             lat = \"latitude\",                                             id = \"occurrence_id\",                                             basin_layer = basin_rast,                                             subc_layer = subc_rast,                                             stream_layer = stream_vect,                                             n_cores = 2) # Show head of output table head(snapped_coordinates)"}]
